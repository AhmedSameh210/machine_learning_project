{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ffe8870",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np                          \n",
    "import pandas as pd\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge \n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "import xgboost as xgb\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import metrics\n",
    "import warnings\n",
    "import pickle\n",
    "warnings.filterwarnings(action='ignore')\n",
    "class Regression:\n",
    "\n",
    "    \n",
    "    def Linear_Regression(self):\n",
    "        linear = LinearRegression()\n",
    "        linear.fit(self.x_train, self.y_train)\n",
    "        \n",
    "        y_pred_test = linear.predict(self.x_test)\n",
    "        \n",
    "        mse = metrics.mean_squared_error(self.y_test, y_pred_test)\n",
    "        mae = metrics.mean_absolute_error(self.y_test, y_pred_test)\n",
    "        r2_score = metrics.r2_score(self.y_test, y_pred_test)\n",
    "        return linear, mse, mae, r2_score * 100\n",
    "    \n",
    "    \n",
    "    def LassoRegression(self):\n",
    "        \n",
    "        lasso_model = Lasso(random_state=42)\n",
    "        lasso_model.fit(self.x_train, self.y_train)\n",
    "        \n",
    "        y_pred = lasso_model.predict(self.x_test)\n",
    "        \n",
    "        mse = metrics.mean_squared_error(self.y_test, y_pred)\n",
    "        mae = metrics.mean_absolute_error(self.y_test, y_pred)\n",
    "        r2 = metrics.r2_score(self.y_test, y_pred)\n",
    "        \n",
    "        return lasso_model, mse, mae, r2 * 100\n",
    "    \n",
    "       \n",
    "    def RidgeRegression(self):\n",
    "        \n",
    "        ridge_model = Ridge(random_state=42)\n",
    "        ridge_model.fit(self.x_train, self.y_train)\n",
    "        \n",
    "        y_pred = ridge_model.predict(self.x_test)\n",
    "        \n",
    "        mse = metrics.mean_squared_error(self.y_test, y_pred)\n",
    "        mae = metrics.mean_absolute_error(self.y_test, y_pred)\n",
    "        r2 = metrics.r2_score(self.y_test, y_pred)\n",
    "        \n",
    "        return ridge_model, mse, mae, r2 * 100\n",
    "    \n",
    "    def SGDRegression(self):\n",
    "        sgd_model = SGDRegressor(random_state=42)\n",
    "        sgd_model.fit(self.x_train, self.y_train)\n",
    "        \n",
    "        y_pred = sgd_model.predict(self.x_test)\n",
    "        \n",
    "        mse = metrics.mean_squared_error(self.y_test, y_pred)\n",
    "        mae = metrics.mean_absolute_error(self.y_test, y_pred)\n",
    "        r2 = metrics.r2_score(self.y_test, y_pred)\n",
    "        \n",
    "        return sgd_model, mse, mae, r2 * 100\n",
    "    \n",
    "    \n",
    "    def Polynomial_Regression(self):\n",
    "        \n",
    "        best_model = None\n",
    "        best_mse = 1e18; best_mae = 1e18; best_r2_score = -1; best_degree = 2\n",
    "\n",
    "        for deg in range(1,1):\n",
    "            poly = PolynomialFeatures(degree = deg)\n",
    "            x_train_poly = poly.fit_transform(self.x_train)\n",
    "            \n",
    "            linear = LinearRegression()\n",
    "            linear.fit(x_train_poly,self.y_train)\n",
    "            \n",
    "            y_pred_test = linear.predict(poly.fit_transform(self.x_test))\n",
    "            \n",
    "            mse = metrics.mean_squared_error(self.y_test, y_pred_test)\n",
    "            mae = metrics.mean_absolute_error(self.y_test, y_pred_test)\n",
    "            r2_score = metrics.r2_score(self.y_test, y_pred_test)\n",
    "            \n",
    "            if(r2_score > best_r2_score):\n",
    "                best_model = linear; best_mse = mse; best_mae = mae; best_r2_score = r2_score; best_degree = deg\n",
    "                \n",
    "        return best_model, best_mse, best_mae, best_r2_score * 100, best_degree\n",
    "    \n",
    "    \n",
    "    def SVR(self):\n",
    "        \n",
    "        svr_model = SVR(kernel='rbf')\n",
    "        svr_model.fit(self.x_train, self.y_train)\n",
    "\n",
    "        y_pred = svr_model.predict(self.x_test)\n",
    "\n",
    "        mse = metrics.mean_squared_error(self.y_test, y_pred)\n",
    "        mae = metrics.mean_absolute_error(self.y_test, y_pred)\n",
    "        r2 = metrics.r2_score(self.y_test, y_pred)\n",
    "\n",
    "        return svr_model, mse, mae, r2 * 100\n",
    "    \n",
    "    \n",
    "    def NeuralNetworkRegression(self):\n",
    "        \n",
    "        nn_model = MLPRegressor(random_state=42, max_iter=10000)  \n",
    "        nn_model.fit(self.x_train, self.y_train)\n",
    "\n",
    "        y_pred = nn_model.predict(self.x_test)\n",
    "\n",
    "        mse = metrics.mean_squared_error(self.y_test, y_pred)\n",
    "        mae = metrics.mean_absolute_error(self.y_test, y_pred)\n",
    "        r2 = metrics.r2_score(self.y_test, y_pred)\n",
    "        \n",
    "        train_mse=metrics.mean_squared_error(self.y_train, nn_model.predict(self.x_train))\n",
    "        return nn_model, mse, mae, r2 * 100\n",
    "    \n",
    "    \n",
    "    def GradientBoostingRegression(self):\n",
    "        \n",
    "        gb_model = GradientBoostingRegressor(random_state=42) \n",
    "        gb_model.fit(self.x_train, self.y_train)\n",
    "\n",
    "        y_pred = gb_model.predict(self.x_test)\n",
    "\n",
    "        mse = metrics.mean_squared_error(self.y_test, y_pred)\n",
    "        mae = metrics.mean_absolute_error(self.y_test, y_pred)\n",
    "        r2 = metrics.r2_score(self.y_test, y_pred)\n",
    "        train_mse=metrics.mean_squared_error(self.y_train, gb_model.predict(self.x_train))\n",
    "            \n",
    "        return gb_model, mse, mae, r2 * 100,train_mse\n",
    "    \n",
    "    \n",
    "    def DecisionTreeRegression(self):\n",
    "        \n",
    "        dt_model = DecisionTreeRegressor(random_state=42) \n",
    "        dt_model.fit(self.x_train, self.y_train)\n",
    "\n",
    "        y_pred = dt_model.predict(self.x_test)\n",
    "\n",
    "        mse = metrics.mean_squared_error(self.y_test, y_pred)\n",
    "        mae = metrics.mean_absolute_error(self.y_test, y_pred)\n",
    "        r2 = metrics.r2_score(self.y_test, y_pred)\n",
    "        train_mse=metrics.mean_squared_error(self.y_train, dt_model.predict(self.x_train))\n",
    "        \n",
    "        return dt_model, mse, mae, r2 * 100,train_mse\n",
    "    \n",
    "    \n",
    "    def ElasticNetRegression(self):\n",
    "        \n",
    "        en_model = ElasticNet(random_state=42)  \n",
    "        en_model.fit(self.x_train, self.y_train)\n",
    "\n",
    "        y_pred = en_model.predict(self.x_test)\n",
    "\n",
    "        mse = metrics.mean_squared_error(self.y_test, y_pred)\n",
    "        mae = metrics.mean_absolute_error(self.y_test, y_pred)\n",
    "        r2 = metrics.r2_score(self.y_test, y_pred)\n",
    "        train_mse=metrics.mean_squared_error(self.y_train, en_model.predict(self.x_train))\n",
    "        \n",
    "        return en_model, mse, mae, r2 * 100,train_mse\n",
    "\n",
    "    \n",
    "    def RandomForestRegression(self):\n",
    "        \n",
    "        rf_model = RandomForestRegressor(n_estimators=100,random_state=42)\n",
    "        rf_model.fit(self.x_train, self.y_train)\n",
    "        \n",
    "        y_pred = rf_model.predict(self.x_test)\n",
    "        \n",
    "        mse = metrics.mean_squared_error(self.y_test, y_pred)\n",
    "        mae = metrics.mean_absolute_error(self.y_test, y_pred)\n",
    "        r2 = metrics.r2_score(self.y_test, y_pred)\n",
    "        train_mse=metrics.mean_squared_error(self.y_train, rf_model.predict(self.x_train))\n",
    "        \n",
    "        return rf_model, mse, mae, r2 * 100,train_mse\n",
    "    \n",
    "    \n",
    "    def AdaBoostRegression(self):\n",
    "        \n",
    "        ab_model = AdaBoostRegressor(random_state=42)\n",
    "        ab_model.fit(self.x_train, self.y_train)\n",
    "        \n",
    "        y_pred = ab_model.predict(self.x_test)\n",
    "        \n",
    "        mse = metrics.mean_squared_error(self.y_test, y_pred)\n",
    "        mae = metrics.mean_absolute_error(self.y_test, y_pred)\n",
    "        r2 = metrics.r2_score(self.y_test, y_pred)\n",
    "        train_mse=metrics.mean_squared_error(self.y_train, ab_model.predict(self.x_train))\n",
    "        return ab_model, mse, mae, r2 * 100,train_mse\n",
    "    \n",
    "    \n",
    "    def BaggingRegression(self):\n",
    "        \n",
    "        bag_model = BaggingRegressor(n_estimators=100,random_state=42)\n",
    "        bag_model.fit(self.x_train, self.y_train)\n",
    "        \n",
    "        y_pred = bag_model.predict(self.x_test)\n",
    "        \n",
    "        mse = metrics.mean_squared_error(self.y_test, y_pred)\n",
    "        mae = metrics.mean_absolute_error(self.y_test, y_pred)\n",
    "        r2 = metrics.r2_score(self.y_test, y_pred)\n",
    "        train_mse=metrics.mean_squared_error(self.y_train, bag_model.predict(self.x_train))\n",
    "        return bag_model, mse, mae, r2 * 100,train_mse\n",
    "    \n",
    "    def KNNLinearRegression(self):\n",
    "        \n",
    "        estimators = [\n",
    "            ('knn', KNeighborsRegressor()),\n",
    "            ('linear', LinearRegression())\n",
    "        ]\n",
    "        stack_model = StackingRegressor(estimators=estimators, final_estimator=LinearRegression())\n",
    "\n",
    "        stack_model.fit(self.x_train, self.y_train)\n",
    "        \n",
    "        y_pred = stack_model.predict(self.x_test)\n",
    "        \n",
    "        mse = metrics.mean_squared_error(self.y_test, y_pred)\n",
    "        mae = metrics.mean_absolute_error(self.y_test, y_pred)\n",
    "        r2 = metrics.r2_score(self.y_test, y_pred)\n",
    "        train_mse=metrics.mean_squared_error(self.y_train, stack_model.predict(self.x_train))\n",
    "        \n",
    "        return stack_model, mse, mae, r2 * 100,train_mse\n",
    "    \n",
    "    \n",
    "    def XGBoostRegression(self):\n",
    "        \n",
    "        xgb_model = xgb.XGBRegressor(n_estimators=100,random_state=42)\n",
    "        xgb_model.fit(self.x_train, self.y_train)\n",
    "        \n",
    "        y_pred = xgb_model.predict(self.x_test)\n",
    "        \n",
    "        mse = metrics.mean_squared_error(self.y_test, y_pred)\n",
    "        mae = metrics.mean_absolute_error(self.y_test, y_pred)\n",
    "        r2 = metrics.r2_score(self.y_test, y_pred)\n",
    "        train_mse=metrics.mean_squared_error(self.y_train, xgb_model.predict(self.x_train))\n",
    "        \n",
    "        return xgb_model, mse, mae, r2 * 100,train_mse\n",
    "        \n",
    "    \n",
    "   \n",
    "    \n",
    "    def FindBestModel(self):\n",
    "        best = self.list_of_models[0] \n",
    "        \n",
    "        for row in self.list_of_models:\n",
    "            if(row[4] > best[4]):\n",
    "                best = row\n",
    "                \n",
    "        return best\n",
    "    \n",
    "    def GetTable(self):\n",
    "        \n",
    "        table_of_models = pd.DataFrame(columns=['name of model','Model','MSE', 'MAE', 'r2_score', 'Polynomial Degree',\"MSE TRAIN\"])\n",
    "        for row in self.list_of_models:\n",
    "            if row[0] != \"Polynomial_Regression\": row.append(None) # degree\n",
    "            table_of_models.loc[len(table_of_models)] = row\n",
    "        table_of_models.sort_values(by='r2_score')\n",
    "        table_of_models.drop(columns=['Model',],inplace=True)\n",
    "        return table_of_models\n",
    "    \n",
    "    \n",
    "    def __init__(self, X, Y):\n",
    "        self.x_train, self.x_test, self.y_train, self.y_test = train_test_split(X, Y, test_size=0.20, shuffle=True, random_state=42)\n",
    "        # index: 0             1     2   3   4  (5 if exist)\n",
    "        # value: name_of_model model MSE MAE r2 poly_degree\n",
    "        self.list_of_models = [\n",
    "            [\"Linear_Regression\", *self.Linear_Regression()],\n",
    "            [\"LassoRegression\", *self.LassoRegression()],\n",
    "            [\"RidgeRegression\", *self.RidgeRegression()],\n",
    "            [\"SGDRegression\", *self.SGDRegression()],\n",
    "            [\"Polynomial_Regression\", *self.Polynomial_Regression()],\n",
    "            [\"SVR\", *self.SVR()],\n",
    "            [\"NeuralNetworkRegression\", *self.NeuralNetworkRegression()],\n",
    "            [\"GradientBoostingRegression\", *self.GradientBoostingRegression()],\n",
    "            [\"DecisionTreeRegression\", *self.DecisionTreeRegression()],\n",
    "            [\"ElasticNetRegression\", *self.ElasticNetRegression()],\n",
    "            [\"RandomForestRegression\", *self.RandomForestRegression()],\n",
    "            [\"AdaBoostRegression\", *self.AdaBoostRegression()],\n",
    "            [\"BaggingRegression\", *self.BaggingRegression()],\n",
    "            [\"KNNLinearRegression\", *self.KNNLinearRegression()],\n",
    "            [\"XGBoostRegression\", *self.XGBoostRegression()]]\n",
    "            \n",
    "        self.best_model = self.FindBestModel()\n",
    "        \n",
    "#         with open(f\"{self.best_model[0]}{self.best_model[4]}.pkl\", \"wb\") as file:\n",
    "#             pickle.dump(self.best_model[1], file)\n",
    "            \n",
    "        self.table_of_models = self.GetTable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "230e52b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class hyperparameter_tuning:\n",
    "    def __init__(self,X,Y):\n",
    "        self.x_train, self.x_test, self.y_train, self.y_test = train_test_split(X, Y, test_size=0.20, shuffle=True, random_state=42)\n",
    "        self.bestParam=[]\n",
    "        regression_methods = [\n",
    "            self.Linear_Regression,\n",
    "            self.LassoRegression,\n",
    "            self.RidgeRegression,\n",
    "            self.SGDRegression,\n",
    "            #self.Polynomial_Regression,\n",
    "            self.SVR,\n",
    "            self.NeuralNetworkRegression,\n",
    "            self.GradientBoostingRegression,\n",
    "            self.DecisionTreeRegression,\n",
    "            self.ElasticNetRegression,\n",
    "            self.RandomForestRegression,\n",
    "            self.AdaBoostRegression,\n",
    "            self.BaggingRegression,\n",
    "            self.KNNLinearRegression,\n",
    "            self.XGBoostRegression\n",
    "        ]\n",
    "        for method in regression_methods:\n",
    "            print(\"Calling:\", method.__name__)\n",
    "            method()\n",
    "            print(self.bestParam[-1])\n",
    "            print(\"<----------------------------------------------------------->\")\n",
    "\n",
    "    def Linear_Regression(self):\n",
    "        param_grid = {\n",
    "        'fit_intercept': [True, False],\n",
    "        'normalize': [True, False]}\n",
    "        linear_regression = LinearRegression()\n",
    "        grid_search = GridSearchCV(estimator=linear_regression, param_grid=param_grid, cv=5)\n",
    "        grid_search.fit(self.x_train, self.y_train)\n",
    "        self.bestParam.append([\"Linear_Regression\",grid_search.best_params_])\n",
    "        \n",
    "        y_train_pred = grid_search.best_estimator_.predict(self.x_train)\n",
    "        r2_train = r2_score(self.y_train, y_train_pred)\n",
    "        print(\"R2 score on training set:\", r2_train)\n",
    "\n",
    "        y_test_pred = grid_search.best_estimator_.predict(self.x_test)\n",
    "        r2_test = r2_score(self.y_test, y_test_pred)\n",
    "        print(\"R2 score on test set:\", r2_test)\n",
    "        \n",
    "    def LassoRegression(self):\n",
    "        lasso = Lasso()\n",
    "        param_grid = {\n",
    "            'alpha': [0.01, 0.1, 1, 10, 100],\n",
    "            'max_iter': [1000, 2000, 3000]  # Example values for max_iter\n",
    "        }\n",
    "        grid_search = GridSearchCV(lasso, param_grid, cv=5)\n",
    "        grid_search.fit(self.x_train, self.y_train)\n",
    "        self.bestParam.append([\"LassoRegression\",grid_search.best_params_])\n",
    "        \n",
    "        y_train_pred = grid_search.best_estimator_.predict(self.x_train)\n",
    "        r2_train = r2_score(self.y_train, y_train_pred)\n",
    "        print(\"R2 score on training set:\", r2_train)\n",
    "\n",
    "        y_test_pred = grid_search.best_estimator_.predict(self.x_test)\n",
    "        r2_test = r2_score(self.y_test, y_test_pred)\n",
    "        print(\"R2 score on test set:\", r2_test)\n",
    "    def RidgeRegression(self):\n",
    "        ridge = Ridge()\n",
    "        param_grid = {\n",
    "            'alpha': [0.01, 0.1, 1, 10, 100],\n",
    "            'max_iter': [1000, 2000, 3000]  # Example values for max_iter\n",
    "        }\n",
    "        grid_search = GridSearchCV(ridge, param_grid, cv=5)\n",
    "        grid_search.fit(self.x_train, self.y_train)\n",
    "        self.bestParam.append([\"RidgeRegression\",grid_search.best_params_])\n",
    "        \n",
    "        y_train_pred = grid_search.best_estimator_.predict(self.x_train)\n",
    "        r2_train = r2_score(self.y_train, y_train_pred)\n",
    "        print(\"R2 score on training set:\", r2_train)\n",
    "\n",
    "        y_test_pred = grid_search.best_estimator_.predict(self.x_test)\n",
    "        r2_test = r2_score(self.y_test, y_test_pred)\n",
    "        print(\"R2 score on test set:\", r2_test)\n",
    "    def SGDRegression(self):\n",
    "        sgd = SGDRegressor()\n",
    "        param_grid = {\n",
    "            'alpha': [0.0001, 0.001, 0.01],\n",
    "            'max_iter': [5000, 6000, 7000],\n",
    "            'learning_rate': ['constant', 'optimal']\n",
    "        }\n",
    "        grid_search = GridSearchCV(sgd, param_grid, cv=5)\n",
    "        grid_search.fit(self.x_train, self.y_train)\n",
    "        self.bestParam.append([\"SGDRegression\",grid_search.best_params_])\n",
    "        \n",
    "        y_train_pred = grid_search.best_estimator_.predict(self.x_train)\n",
    "        r2_train = r2_score(self.y_train, y_train_pred)\n",
    "        print(\"R2 score on training set:\", r2_train)\n",
    "\n",
    "        y_test_pred = grid_search.best_estimator_.predict(self.x_test)\n",
    "        r2_test = r2_score(self.y_test, y_test_pred)\n",
    "        print(\"R2 score on test set:\", r2_test)\n",
    "    def Polynomial_Regression(self):\n",
    "        param_grid = {'polynomialfeatures__degree': [2,3,5]}\n",
    "\n",
    "        pipeline = make_pipeline(PolynomialFeatures(), LinearRegression())\n",
    "        \n",
    "        grid_search = GridSearchCV(pipeline, param_grid, cv=5)\n",
    "        grid_search.fit(self.x_train, self.y_train)\n",
    "        self.bestParam.append([\"Polynomial_Regression\",grid_search.best_params_])\n",
    "        \n",
    "        y_train_pred = grid_search.best_estimator_.predict(self.x_train)\n",
    "        r2_train = r2_score(self.y_train, y_train_pred)\n",
    "        print(\"R2 score on training set:\", r2_train)\n",
    "\n",
    "        y_test_pred = grid_search.best_estimator_.predict(self.x_test)\n",
    "        r2_test = r2_score(self.y_test, y_test_pred)\n",
    "        print(\"R2 score on test set:\", r2_test)\n",
    "    def SVR(self):\n",
    "        param_grid = {\n",
    "            'kernel': ['rbf', 'linear', 'poly'],\n",
    "            'C': [0.1, 1, 10],\n",
    "            'gamma': [0.01, 0.1, 1],\n",
    "            'epsilon': [0.1, 0.2, 0.5]\n",
    "        }\n",
    "        svr = SVR()\n",
    "        grid_search = GridSearchCV(svr, param_grid, cv=5)\n",
    "        grid_search.fit(self.x_train, self.y_train)\n",
    "        self.bestParam.append([\"SVR\",grid_search.best_params_])\n",
    "        \n",
    "        y_train_pred = grid_search.best_estimator_.predict(self.x_train)\n",
    "        r2_train = r2_score(self.y_train, y_train_pred)\n",
    "        print(\"R2 score on training set:\", r2_train)\n",
    "\n",
    "        y_test_pred = grid_search.best_estimator_.predict(self.x_test)\n",
    "        r2_test = r2_score(self.y_test, y_test_pred)\n",
    "        print(\"R2 score on test set:\", r2_test)\n",
    "    def NeuralNetworkRegression(self):\n",
    "        param_grid = {\n",
    "        'hidden_layer_sizes': [(100,), (50, 50), (100, 50, 25)],\n",
    "        'activation': ['relu', 'tanh'],\n",
    "        'solver': ['adam', 'sgd'],\n",
    "        'alpha': [0.0001, 0.001, 0.01],\n",
    "        'learning_rate': ['constant', 'adaptive'],\n",
    "        'max_iter': [100, 200, 300]\n",
    "        }\n",
    "\n",
    "        mlp = MLPRegressor()\n",
    "        grid_search = GridSearchCV(mlp, param_grid, cv=5)\n",
    "        grid_search.fit(self.x_train, self.y_train)\n",
    "        self.bestParam.append([\"NeuralNetworkRegression\",grid_search.best_params_])\n",
    "        \n",
    "        y_train_pred = grid_search.best_estimator_.predict(self.x_train)\n",
    "        r2_train = r2_score(self.y_train, y_train_pred)\n",
    "        print(\"R2 score on training set:\", r2_train)\n",
    "\n",
    "        y_test_pred = grid_search.best_estimator_.predict(self.x_test)\n",
    "        r2_test = r2_score(self.y_test, y_test_pred)\n",
    "        print(\"R2 score on test set:\", r2_test)\n",
    "    def GradientBoostingRegression(self):\n",
    "        param_grid = {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'learning_rate': [0.05, 0.1, 0.2],\n",
    "        'max_depth': [3, 4, 5],\n",
    "        }\n",
    "        gbr = GradientBoostingRegressor()\n",
    "        grid_search = GridSearchCV(gbr, param_grid, cv=5)\n",
    "        grid_search.fit(self.x_train, self.y_train)\n",
    "        self.bestParam.append([\"GradientBoostingRegression\",grid_search.best_params_])\n",
    "        \n",
    "        y_train_pred = grid_search.best_estimator_.predict(self.x_train)\n",
    "        r2_train = r2_score(self.y_train, y_train_pred)\n",
    "        print(\"R2 score on training set:\", r2_train)\n",
    "\n",
    "        y_test_pred = grid_search.best_estimator_.predict(self.x_test)\n",
    "        r2_test = r2_score(self.y_test, y_test_pred)\n",
    "        print(\"R2 score on test set:\", r2_test)\n",
    "    def DecisionTreeRegression(self):\n",
    "        param_grid = {\n",
    "        'max_depth': [None, 5, 10, 15, 20],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4],\n",
    "        }\n",
    "        dt = DecisionTreeRegressor()\n",
    "        grid_search = GridSearchCV(dt, param_grid, cv=5)\n",
    "        grid_search.fit(self.x_train, self.y_train)\n",
    "        self.bestParam.append([\"DecisionTreeRegression\",grid_search.best_params_])\n",
    "        \n",
    "        y_train_pred = grid_search.best_estimator_.predict(self.x_train)\n",
    "        r2_train = r2_score(self.y_train, y_train_pred)\n",
    "        print(\"R2 score on training set:\", r2_train)\n",
    "\n",
    "        y_test_pred = grid_search.best_estimator_.predict(self.x_test)\n",
    "        r2_test = r2_score(self.y_test, y_test_pred)\n",
    "        print(\"R2 score on test set:\", r2_test)\n",
    "    def ElasticNetRegression(self):\n",
    "        param_grid = {\n",
    "            'alpha': [0.1, 0.5, 1.0],\n",
    "            'l1_ratio': [0.1, 0.3, 0.5, 0.7, 0.9],\n",
    "            'max_iter': [1000, 2000, 3000]\n",
    "        }\n",
    "        elastic_net = ElasticNet()\n",
    "        grid_search = GridSearchCV(elastic_net, param_grid, cv=5)\n",
    "        grid_search.fit(self.x_train, self.y_train)\n",
    "        self.bestParam.append([\"ElasticNetRegression\", grid_search.best_params_])\n",
    "        \n",
    "        y_train_pred = grid_search.best_estimator_.predict(self.x_train)\n",
    "        r2_train = r2_score(self.y_train, y_train_pred)\n",
    "        print(\"R2 score on training set:\", r2_train)\n",
    "\n",
    "        y_test_pred = grid_search.best_estimator_.predict(self.x_test)\n",
    "        r2_test = r2_score(self.y_test, y_test_pred)\n",
    "        print(\"R2 score on test set:\", r2_test)\n",
    "    def RandomForestRegression(self):\n",
    "        param_grid = {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'max_depth': [1, 5, 10, 15, 20],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        }\n",
    "        rf = RandomForestRegressor()\n",
    "        grid_search = GridSearchCV(rf, param_grid, cv=5)\n",
    "        grid_search.fit(self.x_train, self.y_train)\n",
    "        self.bestParam.append([\"RandomForestRegression\", grid_search.best_params_])\n",
    "        \n",
    "        y_train_pred = grid_search.best_estimator_.predict(self.x_train)\n",
    "        r2_train = r2_score(self.y_train, y_train_pred)\n",
    "        print(\"R2 score on training set:\", r2_train)\n",
    "\n",
    "        y_test_pred = grid_search.best_estimator_.predict(self.x_test)\n",
    "        r2_test = r2_score(self.y_test, y_test_pred)\n",
    "        print(\"R2 score on test set:\", r2_test)\n",
    "    def AdaBoostRegression(self):\n",
    "        param_grid = {\n",
    "            'n_estimators': [50, 100, 200],\n",
    "            'learning_rate': [0.01, 0.1, 1.0]\n",
    "        }\n",
    "        ada_boost = AdaBoostRegressor()\n",
    "        grid_search = GridSearchCV(ada_boost, param_grid, cv=5)\n",
    "        grid_search.fit(self.x_train, self.y_train)\n",
    "        self.bestParam.append([\"AdaBoostRegression\", grid_search.best_params_])\n",
    "        \n",
    "        y_train_pred = grid_search.best_estimator_.predict(self.x_train)\n",
    "        r2_train = r2_score(self.y_train, y_train_pred)\n",
    "        print(\"R2 score on training set:\", r2_train)\n",
    "\n",
    "        y_test_pred = grid_search.best_estimator_.predict(self.x_test)\n",
    "        r2_test = r2_score(self.y_test, y_test_pred)\n",
    "        print(\"R2 score on test set:\", r2_test)\n",
    "    def BaggingRegression(self):\n",
    "        param_grid = {\n",
    "            'n_estimators': [10, 50, 100],\n",
    "            'max_samples': [0.5, 1.0],\n",
    "            'max_features': [0.5, 1.0],\n",
    "        }\n",
    "        bagging = BaggingRegressor()\n",
    "        grid_search = GridSearchCV(bagging, param_grid, cv=5)\n",
    "        grid_search.fit(self.x_train, self.y_train)\n",
    "        self.bestParam.append([\"BaggingRegression\", grid_search.best_params_])\n",
    "        \n",
    "        y_train_pred = grid_search.best_estimator_.predict(self.x_train)\n",
    "        r2_train = r2_score(self.y_train, y_train_pred)\n",
    "        print(\"R2 score on training set:\", r2_train)\n",
    "\n",
    "        y_test_pred = grid_search.best_estimator_.predict(self.x_test)\n",
    "        r2_test = r2_score(self.y_test, y_test_pred)\n",
    "        print(\"R2 score on test set:\", r2_test)\n",
    "    def KNNLinearRegression(self):\n",
    "        param_grid = {\n",
    "            'n_neighbors': [3, 5, 7, 9, 11],\n",
    "            'weights': ['uniform', 'distance'],\n",
    "            'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "            'p': [1, 2]\n",
    "        }\n",
    "        knn = KNeighborsRegressor()\n",
    "        grid_search = GridSearchCV(knn, param_grid, cv=5)\n",
    "        grid_search.fit(self.x_train, self.y_train)\n",
    "        self.bestParam.append([\"KNNLinearRegression\", grid_search.best_params_])\n",
    "        \n",
    "        y_train_pred = grid_search.best_estimator_.predict(self.x_train)\n",
    "        r2_train = r2_score(self.y_train, y_train_pred)\n",
    "        print(\"R2 score on training set:\", r2_train)\n",
    "\n",
    "        y_test_pred = grid_search.best_estimator_.predict(self.x_test)\n",
    "        r2_test = r2_score(self.y_test, y_test_pred)\n",
    "        print(\"R2 score on test set:\", r2_test)\n",
    "    def XGBoostRegression(self):\n",
    "        param_grid = {\n",
    "            'n_estimators': [100, 200, 300],\n",
    "            'learning_rate': [0.01, 0.1, 0.3],\n",
    "            'max_depth': [3, 5, 7],\n",
    "            'subsample': [0.5, 0.8, 1.0],\n",
    "        }\n",
    "        xgb = XGBRegressor()\n",
    "        grid_search = GridSearchCV(xgb, param_grid, cv=5)\n",
    "        grid_search.fit(self.x_train, self.y_train)\n",
    "        self.bestParam.append([\"XGBoostRegression\", grid_search.best_params_])\n",
    "        \n",
    "        y_train_pred = grid_search.best_estimator_.predict(self.x_train)\n",
    "        r2_train = r2_score(self.y_train, y_train_pred)\n",
    "        print(\"R2 score on training set:\", r2_train)\n",
    "\n",
    "        y_test_pred = grid_search.best_estimator_.predict(self.x_test)\n",
    "        r2_test = r2_score(self.y_test, y_test_pred)\n",
    "        print(\"R2 score on test set:\", r2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65a064c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"PreprocessedDF.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bcc45fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop([\"Unnamed: 0\",\"index\",\"Song\",\"Album\",\"Artist Names\",\"Spotify Link\",\"Song Image\",\"Spotify URI\",\"image_description\",\"color_values\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0caa47f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hot100 Rank</th>\n",
       "      <th>safe_log Song Length(ms)</th>\n",
       "      <th>Popularity</th>\n",
       "      <th>sqrt Acousticness</th>\n",
       "      <th>Danceability</th>\n",
       "      <th>Energy</th>\n",
       "      <th>safe_log Instrumentalness</th>\n",
       "      <th>safe_log Liveness</th>\n",
       "      <th>Loudness</th>\n",
       "      <th>safe_log Speechiness</th>\n",
       "      <th>...</th>\n",
       "      <th>deep dance pop</th>\n",
       "      <th>nursery</th>\n",
       "      <th>hel</th>\n",
       "      <th>nashville indie</th>\n",
       "      <th>alabama rap</th>\n",
       "      <th>boston rock</th>\n",
       "      <th>pop romantico</th>\n",
       "      <th>romanian house</th>\n",
       "      <th>romanian pop</th>\n",
       "      <th>moldovan pop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>44</td>\n",
       "      <td>12.345078</td>\n",
       "      <td>62</td>\n",
       "      <td>0.141421</td>\n",
       "      <td>0.478</td>\n",
       "      <td>0.736</td>\n",
       "      <td>-9.253143</td>\n",
       "      <td>-2.137071</td>\n",
       "      <td>-7.124</td>\n",
       "      <td>-3.304978</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>43</td>\n",
       "      <td>12.579703</td>\n",
       "      <td>63</td>\n",
       "      <td>0.482701</td>\n",
       "      <td>0.588</td>\n",
       "      <td>0.522</td>\n",
       "      <td>-18.420681</td>\n",
       "      <td>-1.427116</td>\n",
       "      <td>-6.254</td>\n",
       "      <td>-3.262305</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>86</td>\n",
       "      <td>12.193256</td>\n",
       "      <td>49</td>\n",
       "      <td>0.689928</td>\n",
       "      <td>0.313</td>\n",
       "      <td>0.600</td>\n",
       "      <td>-10.572528</td>\n",
       "      <td>-0.648174</td>\n",
       "      <td>-7.913</td>\n",
       "      <td>-3.332604</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20</td>\n",
       "      <td>12.038044</td>\n",
       "      <td>43</td>\n",
       "      <td>0.986408</td>\n",
       "      <td>0.503</td>\n",
       "      <td>0.059</td>\n",
       "      <td>-18.420681</td>\n",
       "      <td>-2.273026</td>\n",
       "      <td>-16.131</td>\n",
       "      <td>-3.001750</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50</td>\n",
       "      <td>12.433260</td>\n",
       "      <td>0</td>\n",
       "      <td>0.122066</td>\n",
       "      <td>0.843</td>\n",
       "      <td>0.348</td>\n",
       "      <td>-6.660887</td>\n",
       "      <td>-1.398367</td>\n",
       "      <td>-10.669</td>\n",
       "      <td>-2.909554</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6186</th>\n",
       "      <td>88</td>\n",
       "      <td>12.607165</td>\n",
       "      <td>56</td>\n",
       "      <td>0.107703</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.862</td>\n",
       "      <td>-8.177120</td>\n",
       "      <td>-2.721135</td>\n",
       "      <td>-7.694</td>\n",
       "      <td>-2.780621</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6187</th>\n",
       "      <td>8</td>\n",
       "      <td>12.621663</td>\n",
       "      <td>71</td>\n",
       "      <td>0.434741</td>\n",
       "      <td>0.787</td>\n",
       "      <td>0.799</td>\n",
       "      <td>-18.420681</td>\n",
       "      <td>-1.203973</td>\n",
       "      <td>-4.680</td>\n",
       "      <td>-2.309610</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6188</th>\n",
       "      <td>43</td>\n",
       "      <td>12.353915</td>\n",
       "      <td>60</td>\n",
       "      <td>0.511859</td>\n",
       "      <td>0.684</td>\n",
       "      <td>0.819</td>\n",
       "      <td>-6.229717</td>\n",
       "      <td>-2.180367</td>\n",
       "      <td>-3.309</td>\n",
       "      <td>-1.435485</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6189</th>\n",
       "      <td>7</td>\n",
       "      <td>12.463911</td>\n",
       "      <td>75</td>\n",
       "      <td>0.144222</td>\n",
       "      <td>0.583</td>\n",
       "      <td>0.786</td>\n",
       "      <td>-18.420681</td>\n",
       "      <td>-1.671313</td>\n",
       "      <td>-3.142</td>\n",
       "      <td>-3.503230</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6190</th>\n",
       "      <td>75</td>\n",
       "      <td>11.876360</td>\n",
       "      <td>54</td>\n",
       "      <td>0.594979</td>\n",
       "      <td>0.497</td>\n",
       "      <td>0.762</td>\n",
       "      <td>-9.739500</td>\n",
       "      <td>-1.280134</td>\n",
       "      <td>-4.462</td>\n",
       "      <td>-3.270169</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6191 rows Ã— 776 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Hot100 Rank  safe_log Song Length(ms)  Popularity  sqrt Acousticness  \\\n",
       "0              44                 12.345078          62           0.141421   \n",
       "1              43                 12.579703          63           0.482701   \n",
       "2              86                 12.193256          49           0.689928   \n",
       "3              20                 12.038044          43           0.986408   \n",
       "4              50                 12.433260           0           0.122066   \n",
       "...           ...                       ...         ...                ...   \n",
       "6186           88                 12.607165          56           0.107703   \n",
       "6187            8                 12.621663          71           0.434741   \n",
       "6188           43                 12.353915          60           0.511859   \n",
       "6189            7                 12.463911          75           0.144222   \n",
       "6190           75                 11.876360          54           0.594979   \n",
       "\n",
       "      Danceability  Energy  safe_log Instrumentalness  safe_log Liveness  \\\n",
       "0            0.478   0.736                  -9.253143          -2.137071   \n",
       "1            0.588   0.522                 -18.420681          -1.427116   \n",
       "2            0.313   0.600                 -10.572528          -0.648174   \n",
       "3            0.503   0.059                 -18.420681          -2.273026   \n",
       "4            0.843   0.348                  -6.660887          -1.398367   \n",
       "...            ...     ...                        ...                ...   \n",
       "6186         0.875   0.862                  -8.177120          -2.721135   \n",
       "6187         0.787   0.799                 -18.420681          -1.203973   \n",
       "6188         0.684   0.819                  -6.229717          -2.180367   \n",
       "6189         0.583   0.786                 -18.420681          -1.671313   \n",
       "6190         0.497   0.762                  -9.739500          -1.280134   \n",
       "\n",
       "      Loudness  safe_log Speechiness  ...  deep dance pop  nursery  hel  \\\n",
       "0       -7.124             -3.304978  ...             0.0      0.0  0.0   \n",
       "1       -6.254             -3.262305  ...             0.0      0.0  0.0   \n",
       "2       -7.913             -3.332604  ...             0.0      0.0  0.0   \n",
       "3      -16.131             -3.001750  ...             0.0      0.0  0.0   \n",
       "4      -10.669             -2.909554  ...             0.0      0.0  0.0   \n",
       "...        ...                   ...  ...             ...      ...  ...   \n",
       "6186    -7.694             -2.780621  ...             0.0      0.0  0.0   \n",
       "6187    -4.680             -2.309610  ...             0.0      0.0  0.0   \n",
       "6188    -3.309             -1.435485  ...             0.0      0.0  0.0   \n",
       "6189    -3.142             -3.503230  ...             0.0      0.0  0.0   \n",
       "6190    -4.462             -3.270169  ...             0.0      0.0  0.0   \n",
       "\n",
       "      nashville indie  alabama rap  boston rock  pop romantico  \\\n",
       "0                 0.0          0.0          0.0            0.0   \n",
       "1                 0.0          0.0          0.0            0.0   \n",
       "2                 0.0          0.0          0.0            0.0   \n",
       "3                 0.0          0.0          0.0            0.0   \n",
       "4                 0.0          0.0          0.0            0.0   \n",
       "...               ...          ...          ...            ...   \n",
       "6186              0.0          0.0          0.0            0.0   \n",
       "6187              0.0          0.0          0.0            0.0   \n",
       "6188              0.0          0.0          0.0            0.0   \n",
       "6189              0.0          0.0          0.0            0.0   \n",
       "6190              0.0          0.0          0.0            0.0   \n",
       "\n",
       "      romanian house  romanian pop  moldovan pop  \n",
       "0                0.0           0.0           0.0  \n",
       "1                0.0           0.0           0.0  \n",
       "2                0.0           0.0           0.0  \n",
       "3                0.0           0.0           0.0  \n",
       "4                0.0           0.0           0.0  \n",
       "...              ...           ...           ...  \n",
       "6186             0.0           0.0           0.0  \n",
       "6187             0.0           0.0           0.0  \n",
       "6188             0.0           0.0           0.0  \n",
       "6189             0.0           0.0           0.0  \n",
       "6190             0.0           0.0           0.0  \n",
       "\n",
       "[6191 rows x 776 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6cecc5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=np.array(df[\"Popularity\"])\n",
    "x=np.array(df.drop([\"Popularity\"],axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7dbbbd66",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler=StandardScaler()\n",
    "x=scaler.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6545eb55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling: Linear_Regression\n",
      "R2 score on training set: 0.6391773362774602\n",
      "R2 score on test set: -2.7028155999583746e+27\n",
      "['Linear_Regression', {'fit_intercept': False, 'normalize': True}]\n",
      "<----------------------------------------------------------->\n",
      "Calling: LassoRegression\n",
      "R2 score on training set: 0.6273937085573732\n",
      "R2 score on test set: 0.5643734944097024\n",
      "['LassoRegression', {'alpha': 0.1, 'max_iter': 1000}]\n",
      "<----------------------------------------------------------->\n",
      "Calling: RidgeRegression\n",
      "R2 score on training set: 0.6454968383811319\n",
      "R2 score on test set: 0.5311113684674005\n",
      "['RidgeRegression', {'alpha': 100, 'max_iter': 1000}]\n",
      "<----------------------------------------------------------->\n",
      "Calling: SGDRegression\n",
      "R2 score on training set: -3.1370674160045195e+19\n",
      "R2 score on test set: -1.8561404321121628e+18\n",
      "['SGDRegression', {'alpha': 0.01, 'learning_rate': 'optimal', 'max_iter': 5000}]\n",
      "<----------------------------------------------------------->\n",
      "Calling: SVR\n"
     ]
    }
   ],
   "source": [
    "cls=hyperparameter_tuning(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10cbbdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cls=Regression(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4ec930",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cls.table_of_models[\"MSE\"][10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52cbf4f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
